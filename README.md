# Bem-vindo Ã  DirigIA!

O **DirigIA** Ã© um sistema avanÃ§ado de visÃ£o computacional desenvolvido para o reconhecimento de objetos em veÃ­culos autÃ´nomos. Ele utiliza tÃ©cnicas de Machine Learning, modelos como o YOLOv8, e uma interface grÃ¡fica interativa para oferecer alta precisÃ£o e eficiÃªncia.

---

## ğŸ” VisÃ£o Geral

- **Nome do aplicativo:** DirigIA
- **Tema:** Desenvolvimento de um sistema de visÃ£o computacional para detecÃ§Ã£o de objetos em tempo real.
- **PropÃ³sito:** Aumentar a seguranÃ§a e eficiÃªncia de veÃ­culos autÃ´nomos, possibilitando o reconhecimento de objetos dinÃ¢micos e estÃ¡ticos, utilizando tÃ©cnicas avanÃ§adas de Machine Learning e interfaces intuitivas.

---

## âœ¨ Principais CaracterÃ­sticas

- **DetecÃ§Ã£o em tempo real:** Utiliza o YOLOv8 para identificar e rastrear diversos objetos com alta precisÃ£o.
- **Interface personalizada:** Desenvolvida em PyQt5, com controles interativos e animaÃ§Ãµes dinÃ¢micas.
- **Perfis adaptÃ¡veis:** Ajustes para diferentes parÃ¢metros de detecÃ§Ã£o como **CrÃ­tico**, **Essencial** e **Recomendado**.
- **Treinamento personalizado:** CompatÃ­vel com datasets traduzidos para PT-BR, como o COCO Dataset.
- **Menu flutuante:** Interface touch-friendly para configuraÃ§Ã£o dinÃ¢mica.

---

## âš™ï¸ InstalaÃ§Ã£o

### **Requisitos**
- **Python:** VersÃ£o 3.x
- **Bibliotecas necessÃ¡rias:**
  - PyQt5 (Interface grÃ¡fica e controle de eventos)
  - NumPy (ManipulaÃ§Ã£o numÃ©rica e arrays)
  - OpenCV (Processamento de imagens)
  - Ultralytics (Treinamento e inferÃªncia com YOLOv8)

---

## **Etapas de InstalaÃ§Ã£o**

**1. Clone o repositÃ³rio:**
git clone https://github.com/WeverSilva/DirigIA_Interface_grafica.git
   
**2. Navegue atÃ© o diretÃ³rio do projeto:**
  cd DirigIA

**3. Instale as dependÃªncias:**
  pip install -r requirements.txt

---

## **ğŸš€ Uso**

**Iniciar o aplicativo**

**Para executar o DirigIA, use o comando:**

python DirigIA.py

---

## **ğŸ”§ ConfiguraÃ§Ã£o**

**Arquivos Importantes**

**â–« Dataset-PTBR_Transito_YOLOv8n.yaml:** Define classes, caminhos das imagens e estrutura do dataset.

**â–« Modelo treinado:** Copie o arquivo best.pt (treinado no Google Colab) para o diretÃ³rio principal do projeto.

---

## **ManipulaÃ§Ã£o de ParÃ¢metros**

**â–« Perfis operacionais:** Utilize os botÃµes para alternar entre perfis:

  **â–« CrÃ­tico:** Alta precisÃ£o para objetos essenciais.

  **â–« Recomendado:** EquilÃ­brio entre precisÃ£o e velocidade.

  **â–« Essencial:** ConfiguraÃ§Ã£o rÃ¡pida e simplificada.

---

## **ğŸ—ï¸ Arquitetura do CÃ³digo**

**Principais Componentes**

**â–« JanelaPrincipal:** Gerencia a interface grÃ¡fica, animaÃ§Ãµes e estados (Ligado/Desligado).

**â–« MenuFlutuante:** Controle de perfis operacionais e alteraÃ§Ãµes dinÃ¢micas de plano de fundo.

**â–« MenuFlutuanteConfig:** Permite ajustes avanÃ§ados, como movimentaÃ§Ã£o e personalizaÃ§Ã£o do sistema.

**â–« JbtEsconder:** Esconde a interface para uso otimizado em dispositivos touch.

---

## **ğŸ“Š Treinamento**

**Carregar e Usar Modelos**

**1. Suba o arquivo best.pt para o diretÃ³rio principal.**

**2. Use o seguinte cÃ³digo para carregar o modelo e realizar inferÃªncias:**

from ultralytics import YOLO
model = YOLO("best.pt")
results = model.predict(source="test_image.jpg", save=True)
print(results)

---

## ğŸ¤ ContribuiÃ§Ã£o
**Como Contribuir**
*1. FaÃ§a o fork do repositÃ³rio e crie uma ramificaÃ§Ã£o para suas alteraÃ§Ãµes.*

*2. Envie um pull request com uma descriÃ§Ã£o clara das melhorias ou correÃ§Ãµes propostas.*

---

## ğŸ“œ LicenÃ§a
**O DirigIA estÃ¡ licenciado sob a LicenÃ§a MIT. Consulte o arquivo LICENSE para mais informaÃ§Ãµes.**

---

## ğŸ“¬ Contato
**Para suporte ou dÃºvidas, entre em contato:**

*â–« ğŸ“§ weversonplayofcrist@gmail.com*

---

# Obrigado por utilizar o DirigIA! Este Ã© um passo importante para o avanÃ§o dos veÃ­culos autÃ´nomos com tecnologia de reconhecimento de objetos em tempo real. ğŸš—âœ¨
